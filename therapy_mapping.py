#!/usr/bin/env python3
"""
PART 1: IMPORTS AND CONFIGURATION
Audio-Text Mapping System using Wav2CLIP for Raga-based Music Therapy

This module maps detected Raga embeddings to therapy-related text descriptions
using Wav2CLIP model for multimodal audio-text understanding.

Features:
- Integrates with raga_detection.py output
- Uses Wav2CLIP for audio-text embeddings
- Maps ragas to therapeutic descriptions
- Uses therapy-specific features: Age, Gender, Mental_Condition, Severity, Improvement_Score, Listening_Time
- Creates personalized therapy recommendations
- Saves reports as PDF

Requirements:
    pip install torch torchvision torchaudio
    pip install transformers
    pip install librosa
    pip install numpy
    pip install scikit-learn
    pip install pandas
    pip install sentence-transformers
    pip install reportlab
"""

import os
import json
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
from pathlib import Path
import pickle
import glob

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Check for required libraries
try:
    from transformers import AutoTokenizer, AutoModel
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    logger.warning("Transformers not available. Install with: pip install transformers")

try:
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("Scikit-learn not available. Install with: pip install scikit-learn")

try:
    import librosa
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False
    logger.warning("Librosa not available. Install with: pip install librosa")

try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib import colors
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False
    logger.warning("ReportLab not available. Install with: pip install reportlab")

@dataclass
class TherapyRecommendation:
    """Data class for therapy recommendations"""
    raga_name: str
    patient_profile: Dict[str, Any]
    therapy_type: str
    mood_enhancement: str
    stress_reduction_level: str
    recommended_duration: int  # minutes
    best_time_of_day: str
    therapeutic_benefits: List[str]
    contraindications: List[str]
    confidence_score: float
    audio_similarity_score: float
    personalization_score: float

@dataclass
class PatientProfile:
    """Patient profile from therapy dataset"""
    age: int
    gender: str
    mental_condition: str
    severity: str
    improvement_score: float
    listening_time: float

# PART 2: WAV2CLIP EMBEDDER CLASS

class Wav2CLIPEmbedder:
    """
    Wav2CLIP-inspired audio-text embedding system
    Creates joint embeddings for audio and text in shared space
    """
    
    def __init__(self, model_name: str = "distilbert-base-uncased"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_name = model_name
        
        # Initialize text encoder
        if TRANSFORMERS_AVAILABLE:
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.text_encoder = AutoModel.from_pretrained(model_name)
                self.text_encoder.to(self.device)
                self.text_encoder.eval()
            except Exception as e:
                logger.warning(f"Failed to load transformers model: {e}")
                self.tokenizer = None
                self.text_encoder = None
        else:
            logger.warning("Using dummy text encoder - install transformers for full functionality")
            self.tokenizer = None
            self.text_encoder = None
        
        # Initialize audio encoder (simplified CNN-based)
        self.audio_encoder = self._build_audio_encoder()
        self.audio_encoder.to(self.device)
        self.audio_encoder.eval()
        
        # Projection layers to shared embedding space
        embedding_dim = 256
        self.audio_projection = nn.Linear(512, embedding_dim).to(self.device)
        self.text_projection = nn.Linear(768, embedding_dim).to(self.device)  # BERT hidden size
        
        # Scaler for audio features
        if SKLEARN_AVAILABLE:
            self.scaler = StandardScaler()
        
        logger.info(f"Wav2CLIP embedder initialized on {self.device}")
    
    def _build_audio_encoder(self) -> nn.Module:
        """Build a simple CNN-based audio encoder"""
        return nn.Sequential(
            nn.Conv1d(1, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Conv1d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
    
    def encode_audio(self, audio_features: np.ndarray) -> np.ndarray:
        """Encode audio features to embedding space"""
        try:
            # Ensure audio features are properly shaped
            if len(audio_features.shape) == 1:
                audio_features = audio_features.reshape(1, -1)
            
            # Scale features if scaler is available
            if SKLEARN_AVAILABLE and hasattr(self.scaler, 'scale_'):
                audio_features = self.scaler.transform(audio_features)
            
            # Convert to tensor
            audio_tensor = torch.FloatTensor(audio_features).unsqueeze(1).to(self.device)
            
            # Encode through audio encoder
            with torch.no_grad():
                audio_embedding = self.audio_encoder(audio_tensor)
                audio_embedding = self.audio_projection(audio_embedding)
            
            return audio_embedding.cpu().numpy()
            
        except Exception as e:
            logger.error(f"Audio encoding failed: {e}")
            return np.zeros((1, 256))
    
    def encode_text(self, text: str) -> np.ndarray:
        """Encode text to embedding space"""
        try:
            if not TRANSFORMERS_AVAILABLE or self.tokenizer is None:
                # Return dummy embedding
                return np.random.randn(1, 256)
            
            # Tokenize text
            inputs = self.tokenizer(
                text, 
                return_tensors="pt", 
                padding=True, 
                truncation=True, 
                max_length=512
            ).to(self.device)
            
            # Encode through text encoder
            with torch.no_grad():
                outputs = self.text_encoder(**inputs)
                text_embedding = outputs.last_hidden_state.mean(dim=1)  # Mean pooling
                text_embedding = self.text_projection(text_embedding)
            
            return text_embedding.cpu().numpy()
            
        except Exception as e:
            logger.error(f"Text encoding failed: {e}")
            return np.zeros((1, 256))
    
    def compute_similarity(self, audio_embedding: np.ndarray, text_embedding: np.ndarray) -> float:
        """Compute cosine similarity between audio and text embeddings"""
        try:
            if SKLEARN_AVAILABLE:
                similarity = cosine_similarity(audio_embedding.reshape(1, -1), 
                                             text_embedding.reshape(1, -1))[0, 0]
            else:
                # Manual cosine similarity
                audio_norm = np.linalg.norm(audio_embedding)
                text_norm = np.linalg.norm(text_embedding)
                if audio_norm == 0 or text_norm == 0:
                    similarity = 0.0
                else:
                    similarity = np.dot(audio_embedding.flatten(), text_embedding.flatten()) / (audio_norm * text_norm)
            
            return float(similarity)
            
        except Exception as e:
            logger.error(f"Similarity computation failed: {e}")
            return 0.0
        
# PART 3: MAIN CLASS INITIALIZATION AND THERAPY PROFILES

class RagaTherapyMapper:
    """Main class for mapping ragas to therapy recommendations"""
    
    def __init__(self):
        self.embedder = Wav2CLIPEmbedder()
        self.therapy_profiles = self._load_therapy_profiles()
        self.dataset_path = "data/Final_dataset_s.csv"  # CORRECTED PATH
        self.mapping_folder = "mapping_output"
        self.raga_detection_output = None
        
        # Create output directory
        os.makedirs(self.mapping_folder, exist_ok=True)
        
        # Load dataset with improved error handling
        self.therapy_dataset = self._load_therapy_dataset()
        
        logger.info("RagaTherapyMapper initialized")
    
    def _load_therapy_profiles(self) -> Dict[str, Dict]:
        """Load comprehensive therapy profiles for each raga"""
        
        therapy_profiles = {
            "Bhairav": {
                "primary_emotion": "spiritual awakening",
                "therapeutic_applications": [
                    "morning meditation", "anxiety reduction", "spiritual healing",
                    "depression management", "focus enhancement"
                ],
                "psychological_effects": [
                    "calming mind", "reducing mental agitation", "promoting introspection",
                    "enhancing spiritual connection", "reducing negative thoughts"
                ],
                "physiological_effects": [
                    "lowering heart rate", "reducing cortisol levels", "improving breathing",
                    "muscle relaxation", "blood pressure regulation"
                ],
                "target_conditions": [
                    "anxiety disorders", "depression", "insomnia", "ADHD", "PTSD"
                ],
                "best_time": "morning (5-8 AM)",
                "session_guidelines": {
                    "duration": "20-30 minutes",
                    "volume": "low to moderate",
                    "environment": "quiet, peaceful space",
                    "position": "sitting or lying down"
                },
                "contraindications": ["severe depression episodes", "psychotic disorders"]
            },
            
            "Yaman": {
                "primary_emotion": "peace and romance",
                "therapeutic_applications": [
                    "stress relief", "relationship therapy", "emotional healing",
                    "sleep preparation", "mood enhancement"
                ],
                "psychological_effects": [
                    "emotional balance", "reducing stress", "promoting love and compassion",
                    "enhancing creativity", "improving mood"
                ],
                "physiological_effects": [
                    "relaxing nervous system", "improving sleep quality", "reducing tension",
                    "enhancing immune function", "promoting healing"
                ],
                "target_conditions": [
                    "stress disorders", "relationship issues", "insomnia", "chronic fatigue"
                ],
                "best_time": "evening (6-9 PM)",
                "session_guidelines": {
                    "duration": "30-45 minutes",
                    "volume": "moderate",
                    "environment": "comfortable, warm lighting",
                    "position": "relaxed sitting or lying"
                },
                "contraindications": ["manic episodes", "severe agitation"]
            },
            
            "Kafi": {
                "primary_emotion": "devotion and surrender",
                "therapeutic_applications": [
                    "grief counseling", "spiritual healing", "letting go therapy",
                    "acceptance training", "emotional release"
                ],
                "psychological_effects": [
                    "emotional release", "promoting acceptance", "reducing attachment",
                    "enhancing surrender", "processing grief"
                ],
                "physiological_effects": [
                    "deep relaxation", "releasing emotional tension", "improving circulation",
                    "balancing hormones", "reducing inflammation"
                ],
                "target_conditions": [
                    "grief and loss", "attachment disorders", "emotional trauma", "addiction recovery"
                ],
                "best_time": "night (9 PM - 12 AM)",
                "session_guidelines": {
                    "duration": "25-40 minutes",
                    "volume": "low to moderate",
                    "environment": "dimly lit, sacred space",
                    "position": "comfortable, eyes closed"
                },
                "contraindications": ["severe depression", "suicidal ideation"]
            },
            
            "Malkauns": {
                "primary_emotion": "deep contemplation",
                "therapeutic_applications": [
                    "deep meditation", "trauma processing", "shadow work",
                    "existential therapy", "consciousness expansion"
                ],
                "psychological_effects": [
                    "deep introspection", "accessing subconscious", "processing trauma",
                    "enhancing awareness", "spiritual transformation"
                ],
                "physiological_effects": [
                    "deep nervous system relaxation", "activating parasympathetic response",
                    "improving neural plasticity", "enhancing recovery"
                ],
                "target_conditions": [
                    "complex PTSD", "dissociative disorders", "chronic pain", "addiction"
                ],
                "best_time": "late night (11 PM - 2 AM)",
                "session_guidelines": {
                    "duration": "45-60 minutes",
                    "volume": "very low",
                    "environment": "completely dark, silent",
                    "position": "lying down, eyes closed"
                },
                "contraindications": ["psychotic disorders", "severe anxiety", "claustrophobia"]
            },
            
            "Bilawal": {
                "primary_emotion": "joy and optimism",
                "therapeutic_applications": [
                    "depression treatment", "mood elevation", "energy enhancement",
                    "motivation building", "positive psychology interventions"
                ],
                "psychological_effects": [
                    "mood elevation", "increasing optimism", "enhancing motivation",
                    "building confidence", "promoting positive thinking"
                ],
                "physiological_effects": [
                    "increasing serotonin", "boosting energy levels", "improving metabolism",
                    "enhancing circulation", "strengthening immune system"
                ],
                "target_conditions": [
                    "depression", "seasonal affective disorder", "low energy", "lack of motivation"
                ],
                "best_time": "morning (8-11 AM)",
                "session_guidelines": {
                    "duration": "20-35 minutes",
                    "volume": "moderate to high",
                    "environment": "bright, open space",
                    "position": "sitting upright or standing"
                },
                "contraindications": ["manic episodes", "severe agitation", "hyperactivity disorders"]
            },
            
            "Todi": {
                "primary_emotion": "melancholy and healing",
                "therapeutic_applications": [
                    "emotional processing", "cathartic release", "healing trauma",
                    "processing sadness", "emotional integration"
                ],
                "psychological_effects": [
                    "emotional catharsis", "processing difficult emotions", "healing wounds",
                    "promoting emotional intelligence", "enhancing empathy"
                ],
                "physiological_effects": [
                    "releasing emotional tension", "improving emotional regulation",
                    "reducing stress hormones", "promoting healing"
                ],
                "target_conditions": [
                    "emotional trauma", "complicated grief", "emotional numbness", "relationship trauma"
                ],
                "best_time": "morning (6-9 AM)",
                "session_guidelines": {
                    "duration": "30-45 minutes",
                    "volume": "low to moderate",
                    "environment": "safe, comfortable space",
                    "position": "comfortable, tissues available"
                },
                "contraindications": ["severe depression", "suicidal ideation", "recent trauma"]
            }
        }
        
        return therapy_profiles

# PART 4: DATA LOADING AND CLEANING (CORRECTED)

    def _load_therapy_dataset(self) -> pd.DataFrame:
        """Load the therapy dataset with specified features - CORRECTED VERSION"""
        
        try:
            if not os.path.exists(self.dataset_path):
                logger.warning(f"Therapy dataset not found: {self.dataset_path}")
                # Create sample data for demonstration
                return self._create_comprehensive_sample_data()
            
            # Load dataset
            df = pd.read_csv(self.dataset_path)
            logger.info(f"Original dataset shape: {df.shape}")
            logger.info(f"Original columns: {list(df.columns)}")
            
            # Select only therapy-related features
            therapy_features = ['Age', 'Gender', 'Mental_Condition', 'Severity', 
                              'Improvement_Score', 'Listening_Time', 'Raga']
            
            # Check if all required columns exist
            missing_cols = [col for col in therapy_features if col not in df.columns]
            available_cols = [col for col in therapy_features if col in df.columns]
            
            if missing_cols:
                logger.warning(f"Missing columns in dataset: {missing_cols}")
                logger.info(f"Available columns: {available_cols}")
                
                # If we're missing critical therapy columns, create sample data
                if len(available_cols) < 3:
                    logger.warning("Too few therapy columns available, creating comprehensive sample data")
                    return self._create_comprehensive_sample_data()
                
                df = df[available_cols]
            else:
                df = df[therapy_features]
            
            # Clean the data
            df = self._clean_therapy_data(df)
            
            if len(df) == 0:
                logger.warning("Dataset is empty after cleaning, creating sample data")
                return self._create_comprehensive_sample_data()
            
            logger.info(f"Loaded therapy dataset: {df.shape}")
            logger.info(f"Final columns: {list(df.columns)}")
            
            return df
            
        except Exception as e:
            logger.error(f"Failed to load therapy dataset: {e}")
            logger.info("Creating comprehensive sample therapy data for demonstration")
            return self._create_comprehensive_sample_data()
    
    def _clean_therapy_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Clean and validate therapy data - CORRECTED VERSION"""
        
        logger.info("Cleaning therapy data...")
        
        # Remove rows with missing critical data
        initial_rows = len(df)
        
        # Create a copy to avoid SettingWithCopyWarning
        df = df.copy()
        
        # Handle missing values more carefully
        columns_to_clean = ['Age', 'Gender', 'Mental_Condition', 'Severity', 'Improvement_Score', 'Listening_Time', 'Raga']
        
        for col in columns_to_clean:
            if col in df.columns:
                # Remove rows where this column is null
                df = df[df[col].notna()]
                
                # Convert data types appropriately
                if col == 'Age':
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    df = df[df[col].notna()]
                    # Filter reasonable age range
                    df = df[(df[col] >= 1) & (df[col] <= 120)]
                    df[col] = df[col].astype(int)
                elif col in ['Improvement_Score', 'Listening_Time']:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    df = df[df[col].notna()]
                    # Filter reasonable ranges
                    if col == 'Improvement_Score':
                        df = df[(df[col] >= 0) & (df[col] <= 10)]
                    elif col == 'Listening_Time':
                        df = df[(df[col] >= 0) & (df[col] <= 300)]  # Max 5 hours
                else:
                    df[col] = df[col].astype(str)
                    # Remove rows with empty strings
                    df = df[df[col].str.strip() != '']
        
        final_rows = len(df)
        logger.info(f"Data cleaning: {initial_rows} -> {final_rows} rows")
        
        if final_rows == 0:
            logger.warning("All data was filtered out during cleaning!")
            return self._create_comprehensive_sample_data()
        
        return df.reset_index(drop=True)
    
    def _create_comprehensive_sample_data(self) -> pd.DataFrame:
        """Create comprehensive sample therapy data for demonstration - CORRECTED VERSION"""
        
        logger.info("Creating comprehensive sample therapy data...")
        
        # Comprehensive sample data representing diverse therapy cases
        sample_data = [
            # Anxiety cases
            {"Age": 25, "Gender": "Female", "Mental_Condition": "Anxiety", "Severity": "Moderate", 
             "Improvement_Score": 6.2, "Listening_Time": 30, "Raga": "Yaman"},
            {"Age": 32, "Gender": "Male", "Mental_Condition": "Anxiety", "Severity": "Severe", 
             "Improvement_Score": 4.2, "Listening_Time": 35, "Raga": "Bhairav"},
            {"Age": 28, "Gender": "Female", "Mental_Condition": "Social_Anxiety", "Severity": "Moderate", 
             "Improvement_Score": 7.6, "Listening_Time": 25, "Raga": "Yaman"},
            {"Age": 24, "Gender": "Male", "Mental_Condition": "Performance_Anxiety", "Severity": "Moderate", 
             "Improvement_Score": 7.8, "Listening_Time": 25, "Raga": "Yaman"},
            {"Age": 31, "Gender": "Female", "Mental_Condition": "Panic_Disorder", "Severity": "Severe", 
             "Improvement_Score": 4.3, "Listening_Time": 20, "Raga": "Bhairav"},
            
            # Depression cases
            {"Age": 35, "Gender": "Male", "Mental_Condition": "Depression", "Severity": "Severe", 
             "Improvement_Score": 3.1, "Listening_Time": 45, "Raga": "Bhairav"},
            {"Age": 32, "Gender": "Female", "Mental_Condition": "Depression", "Severity": "Mild", 
             "Improvement_Score": 8.5, "Listening_Time": 25, "Raga": "Bilawal"},
            {"Age": 29, "Gender": "Male", "Mental_Condition": "Seasonal_Depression", "Severity": "Moderate", 
             "Improvement_Score": 6.8, "Listening_Time": 30, "Raga": "Bilawal"},
            
            # PTSD and Trauma cases
            {"Age": 42, "Gender": "Female", "Mental_Condition": "PTSD", "Severity": "High", 
             "Improvement_Score": 4.5, "Listening_Time": 25, "Raga": "Malkauns"},
            {"Age": 38, "Gender": "Male", "Mental_Condition": "Complex_PTSD", "Severity": "Severe", 
             "Improvement_Score": 3.8, "Listening_Time": 40, "Raga": "Malkauns"},
            {"Age": 34, "Gender": "Female", "Mental_Condition": "Emotional_Trauma", "Severity": "High", 
             "Improvement_Score": 5.2, "Listening_Time": 35, "Raga": "Todi"},
            
            # Sleep and Insomnia cases
            {"Age": 28, "Gender": "Male", "Mental_Condition": "Insomnia", "Severity": "Moderate", 
             "Improvement_Score": 7.3, "Listening_Time": 35, "Raga": "Kafi"},
            {"Age": 45, "Gender": "Female", "Mental_Condition": "Sleep_Disorder", "Severity": "Severe", 
             "Improvement_Score": 5.1, "Listening_Time": 40, "Raga": "Kafi"},
            
            # Chronic Pain
            {"Age": 55, "Gender": "Female", "Mental_Condition": "Chronic_Pain", "Severity": "High", 
             "Improvement_Score": 5.8, "Listening_Time": 40, "Raga": "Todi"},
            {"Age": 48, "Gender": "Female", "Mental_Condition": "Fibromyalgia", "Severity": "High", 
             "Improvement_Score": 5.9, "Listening_Time": 45, "Raga": "Malkauns"},
            
            # ADHD and Attention Disorders
            {"Age": 19, "Gender": "Male", "Mental_Condition": "ADHD", "Severity": "Mild", 
             "Improvement_Score": 8.1, "Listening_Time": 20, "Raga": "Bilawal"},
            {"Age": 12, "Gender": "Female", "Mental_Condition": "ADHD", "Severity": "Moderate", 
             "Improvement_Score": 6.9, "Listening_Time": 15, "Raga": "Bhairav"},
            
            # Bipolar and Mood Disorders
            {"Age": 38, "Gender": "Female", "Mental_Condition": "Bipolar", "Severity": "Moderate", 
             "Improvement_Score": 6.7, "Listening_Time": 30, "Raga": "Yaman"},
            {"Age": 41, "Gender": "Female", "Mental_Condition": "Borderline_PD", "Severity": "Severe", 
             "Improvement_Score": 4.1, "Listening_Time": 35, "Raga": "Todi"},
            
            # Stress and Work-related issues
            {"Age": 50, "Gender": "Male", "Mental_Condition": "Stress", "Severity": "Moderate", 
             "Improvement_Score": 7.1, "Listening_Time": 30, "Raga": "Kafi"},
            {"Age": 37, "Gender": "Male", "Mental_Condition": "Work_Stress", "Severity": "Mild", 
             "Improvement_Score": 8.3, "Listening_Time": 25, "Raga": "Yaman"},
            {"Age": 43, "Gender": "Female", "Mental_Condition": "Burnout", "Severity": "High", 
             "Improvement_Score": 4.7, "Listening_Time": 35, "Raga": "Kafi"},
            
            # OCD and Related Disorders
            {"Age": 29, "Gender": "Female", "Mental_Condition": "OCD", "Severity": "High", 
             "Improvement_Score": 5.3, "Listening_Time": 40, "Raga": "Malkauns"},
            {"Age": 26, "Gender": "Female", "Mental_Condition": "Body_Dysmorphia", "Severity": "High", 
             "Improvement_Score": 5.6, "Listening_Time": 30, "Raga": "Bilawal"},
            
            # Additional diverse cases
            {"Age": 60, "Gender": "Male", "Mental_Condition": "Dementia", "Severity": "Moderate", 
             "Improvement_Score": 6.8, "Listening_Time": 20, "Raga": "Bhairav"},
            {"Age": 23, "Gender": "Female", "Mental_Condition": "Eating_Disorder", "Severity": "Severe", 
             "Improvement_Score": 4.7, "Listening_Time": 30, "Raga": "Todi"},
            {"Age": 40, "Gender": "Male", "Mental_Condition": "Addiction", "Severity": "High", 
             "Improvement_Score": 3.8, "Listening_Time": 45, "Raga": "Kafi"},
            {"Age": 52, "Gender": "Male", "Mental_Condition": "Grief", "Severity": "High", 
             "Improvement_Score": 5.1, "Listening_Time": 50, "Raga": "Todi"},
            {"Age": 33, "Gender": "Male", "Mental_Condition": "Autism", "Severity": "Moderate", 
             "Improvement_Score": 7.4, "Listening_Time": 40, "Raga": "Bhairav"},
            {"Age": 44, "Gender": "Male", "Mental_Condition": "Anger_Issues", "Severity": "Moderate", 
             "Improvement_Score": 6.9, "Listening_Time": 35, "Raga": "Malkauns"},
        ]
        
        df = pd.DataFrame(sample_data)
        logger.info(f"Created comprehensive sample therapy dataset: {df.shape}")
        
        # Normalize improvement scores to 0-1 range for consistency
        df['Improvement_Score'] = df['Improvement_Score'] / 10.0
        
        # Display sample of created data
        logger.info(f"Sample data preview:")
        logger.info(f"Unique conditions: {len(df['Mental_Condition'].unique())} types")
        logger.info(f"Unique ragas: {sorted(df['Raga'].unique())}")
        logger.info(f"Age range: {df['Age'].min()}-{df['Age'].max()}")
        
        return df
    
# PART 5: RAGA DETECTION FILE LOADING (CORRECTED)

    def check_raga_detection_output(self) -> bool:
        """Check if raga_detection.py has been run and output exists - CORRECTED VERSION"""
        
        # Check if results directory exists
        if not os.path.exists("results"):
            logger.warning("Results directory not found")
            return False
        
        # Check for any prediction files using the actual pattern
        results_dir = Path("results/json_values")
        if not results_dir.exists():
            logger.warning("results/json_values directory not found")
            return False
        
        # Look for performance and prediction files
        performance_files = list(results_dir.glob("*performance*.json"))
        prediction_files = list(results_dir.glob("*prediction*.json"))
        
        if performance_files or prediction_files:
            logger.info(f"Found raga detection output: {len(prediction_files)} prediction files, {len(performance_files)} performance files")
            return True
        
        # Check for saved model or classifier
        if os.path.exists("enhanced_raga_classifier.pkl") or os.path.exists("raga_classifier.pkl"):
            logger.info("Found saved classifier")
            return True
        
        logger.warning("No raga detection output found")
        return False
    
    def load_raga_detection_results(self) -> Dict[str, Any]:
        """Load results from raga_detection.py with correct file patterns - CORRECTED VERSION"""
        
        results = {
            "model_performance": None,
            "predictions": [],
            "classifier_available": False
        }
        
        try:
            results_dir = Path("results/json_values")
            
            if not results_dir.exists():
                logger.error("results/json_values directory not found")
                return results
            
            # Load model performance with exact filename
            performance_file = results_dir / "enhanced_model_performance.json"
            if performance_file.exists():
                with open(performance_file, 'r') as f:
                    results["model_performance"] = json.load(f)
                logger.info(f"Loaded model performance from {performance_file}")
            else:
                logger.warning(f"Performance file not found: {performance_file}")
            
            # Load predictions with pattern matching
            prediction_files = list(results_dir.glob("enhanced_prediction_*.json"))
            
            if not prediction_files:
                # Try alternative pattern
                prediction_files = list(results_dir.glob("*prediction*.json"))
            
            logger.info(f"Found {len(prediction_files)} prediction files")
            
            for pred_file in prediction_files:
                try:
                    with open(pred_file, 'r') as f:
                        prediction_data = json.load(f)
                        results["predictions"].append(prediction_data)
                        logger.info(f"Loaded prediction from {pred_file}")
                except Exception as e:
                    logger.warning(f"Could not load prediction file {pred_file}: {e}")
            
            # Check for classifier
            if os.path.exists("enhanced_raga_classifier.pkl"):
                results["classifier_available"] = True
                logger.info("Enhanced classifier found")
            elif os.path.exists("raga_classifier.pkl"):
                results["classifier_available"] = True
                logger.info("Standard classifier found")
            
            logger.info(f"Loaded {len(results['predictions'])} prediction results")
            return results
            
        except Exception as e:
            logger.error(f"Failed to load raga detection results: {e}")
            return results
        
# PART 6: RECOMMENDATION ENGINE METHODS

    def create_personalized_recommendation(self, raga_name: str, patient_profile: PatientProfile, 
                                         audio_features: Optional[np.ndarray] = None) -> TherapyRecommendation:
        """Create personalized therapy recommendation based on raga and patient profile"""
        
        # Get base therapy profile for raga
        base_profile = self.therapy_profiles.get(raga_name, {})
        
        if not base_profile:
            logger.warning(f"No therapy profile found for raga: {raga_name}")
            # Create basic recommendation
            return TherapyRecommendation(
                raga_name=raga_name,
                patient_profile=patient_profile.__dict__,
                therapy_type="general music therapy",
                mood_enhancement="mild",
                stress_reduction_level="moderate",
                recommended_duration=30,
                best_time_of_day="any time",
                therapeutic_benefits=["relaxation", "mood improvement"],
                contraindications=["none known"],
                confidence_score=0.5,
                audio_similarity_score=0.0,
                personalization_score=0.5
            )
        
        # Personalize based on patient profile
        personalized_duration = self._calculate_duration(base_profile, patient_profile)
        personalized_benefits = self._get_personalized_benefits(base_profile, patient_profile)
        therapy_type = self._determine_therapy_type(base_profile, patient_profile)
        mood_enhancement = self._assess_mood_enhancement(base_profile, patient_profile)
        stress_reduction = self._assess_stress_reduction(base_profile, patient_profile)
        
        # Calculate personalization score
        personalization_score = self._calculate_personalization_score(patient_profile)
        
        # Calculate audio similarity if features provided
        audio_similarity = 0.0
        if audio_features is not None:
            therapy_description = self._generate_therapy_description(base_profile, patient_profile)
            audio_emb = self.embedder.encode_audio(audio_features)
            text_emb = self.embedder.encode_text(therapy_description)
            audio_similarity = self.embedder.compute_similarity(audio_emb, text_emb)
        
        # Determine contraindications
        contraindications = self._assess_contraindications(base_profile, patient_profile)
        
        # Calculate confidence score
        confidence_score = self._calculate_confidence_score(base_profile, patient_profile, audio_similarity)
        
        return TherapyRecommendation(
            raga_name=raga_name,
            patient_profile=patient_profile.__dict__,
            therapy_type=therapy_type,
            mood_enhancement=mood_enhancement,
            stress_reduction_level=stress_reduction,
            recommended_duration=personalized_duration,
            best_time_of_day=base_profile.get("best_time", "any time"),
            therapeutic_benefits=personalized_benefits,
            contraindications=contraindications,
            confidence_score=confidence_score,
            audio_similarity_score=audio_similarity,
            personalization_score=personalization_score
        )
    
    def _calculate_duration(self, base_profile: Dict, patient_profile: PatientProfile) -> int:
        """Calculate personalized session duration"""
        
        base_duration = 30  # default
        
        # Parse base duration
        duration_str = base_profile.get("session_guidelines", {}).get("duration", "30 minutes")
        try:
            base_duration = int(duration_str.split('-')[0])
        except:
            base_duration = 30
        
        # Adjust based on age
        if patient_profile.age < 18:
            base_duration = min(base_duration, 20)  # Shorter for children
        elif patient_profile.age > 65:
            base_duration = min(base_duration, 25)  # Shorter for elderly
        
        # Adjust based on severity
        if patient_profile.severity.lower() in ['severe', 'high']:
            base_duration = min(base_duration, 20)  # Shorter for severe cases
        elif patient_profile.severity.lower() in ['mild', 'low']:
            base_duration = min(base_duration + 10, 45)  # Longer for mild cases
        
        # Adjust based on listening time preference
        if patient_profile.listening_time < 20:
            base_duration = min(base_duration, patient_profile.listening_time + 5)
        
        return max(15, min(base_duration, 60))  # Ensure reasonable bounds
    
    def _get_personalized_benefits(self, base_profile: Dict, patient_profile: PatientProfile) -> List[str]:
        """Get personalized therapeutic benefits"""
        
        base_benefits = base_profile.get("therapeutic_applications", [])
        psychological_effects = base_profile.get("psychological_effects", [])
        
        # Combine and filter based on patient condition
        all_benefits = base_benefits + psychological_effects
        
        # Filter based on mental condition
        condition = patient_profile.mental_condition.lower()
        relevant_benefits = []
        
        for benefit in all_benefits:
            benefit_lower = benefit.lower()
            if condition in benefit_lower or any(word in benefit_lower for word in condition.split()):
                relevant_benefits.append(benefit)
        
        # Add general benefits if none found
        if not relevant_benefits:
            relevant_benefits = base_benefits[:3]  # Take first 3 as default
        
        return relevant_benefits[:5]  # Limit to 5 benefits
    
    def _determine_therapy_type(self, base_profile: Dict, patient_profile: PatientProfile) -> str:
        """Determine specific therapy type"""
        
        condition = patient_profile.mental_condition.lower()
        
        if "anxiety" in condition:
            return "anxiety-focused music therapy"
        elif "depression" in condition:
            return "mood-enhancing music therapy"
        elif "ptsd" in condition or "trauma" in condition:
            return "trauma-informed music therapy"
        elif "adhd" in condition or "attention" in condition:
            return "focus-enhancing music therapy"
        elif "insomnia" in condition or "sleep" in condition:
            return "sleep-induction music therapy"
        else:
            return f"{base_profile.get('primary_emotion', 'general')} music therapy"
    
    def _assess_mood_enhancement(self, base_profile: Dict, patient_profile: PatientProfile) -> str:
        """Assess expected mood enhancement level"""
        
        # Base assessment from raga
        raga_mood_map = {
            "Bhairav": "calming",
            "Yaman": "uplifting", 
            "Kafi": "soothing",
            "Malkauns": "deeply calming",
            "Bilawal": "energizing",
            "Todi": "cathartic"
        }
        
        base_mood = raga_mood_map.get(base_profile.get("primary_emotion", ""), "moderate")
        
        # Adjust based on severity and improvement score
        if patient_profile.severity.lower() in ['severe', 'high']:
            if patient_profile.improvement_score > 0.7:
                return f"strong {base_mood}"
            else:
                return f"gentle {base_mood}"
        else:
            return f"moderate {base_mood}"
    
    def _assess_stress_reduction(self, base_profile: Dict, patient_profile: PatientProfile) -> str:
        """Assess stress reduction potential"""
        
        stress_effects = base_profile.get("physiological_effects", [])
        stress_keywords = ["stress", "tension", "cortisol", "relaxation", "calm"]
        
        stress_related = [effect for effect in stress_effects 
                         if any(keyword in effect.lower() for keyword in stress_keywords)]
        
        if len(stress_related) >= 3:
            return "high stress reduction"
        elif len(stress_related) >= 1:
            return "moderate stress reduction"
        else:
            return "mild stress reduction"
    
    def _assess_contraindications(self, base_profile: Dict, patient_profile: PatientProfile) -> List[str]:
        """Assess contraindications for the patient"""
        
        base_contraindications = base_profile.get("contraindications", [])
        patient_condition = patient_profile.mental_condition.lower()
        
        # Check if patient condition matches any contraindications
        relevant_contraindications = []
        
        for contraindication in base_contraindications:
            if any(word in patient_condition for word in contraindication.lower().split()):
                relevant_contraindications.append(f"Caution: {contraindication}")
        
        # Add severity-based contraindications
        if patient_profile.severity.lower() in ['severe', 'critical']:
            relevant_contraindications.append("Monitor closely due to severe condition")
        
        # Add age-based considerations
        if patient_profile.age < 16:
            relevant_contraindications.append("Requires parental supervision")
        elif patient_profile.age > 75:
            relevant_contraindications.append("Monitor for fatigue")
        
        return relevant_contraindications if relevant_contraindications else ["None identified"]
    
    def _calculate_personalization_score(self, patient_profile: PatientProfile) -> float:
        """Calculate how well we can personalize for this patient"""
        
        score = 0.0
        
        # Age factor
        if 18 <= patient_profile.age <= 65:
            score += 0.2
        else:
            score += 0.1
        
        # Gender factor (we have info)
        if patient_profile.gender.lower() in ['male', 'female', 'other']:
            score += 0.1
        
        # Mental condition specificity
        if len(patient_profile.mental_condition) > 3:
            score += 0.3
        
        # Severity information
        if patient_profile.severity.lower() in ['mild', 'moderate', 'severe', 'low', 'high']:
            score += 0.2
        
        # Improvement score validity
        if 0 <= patient_profile.improvement_score <= 1:
            score += 0.1
        
        # Listening time validity
        if 5 <= patient_profile.listening_time <= 120:
            score += 0.1
        
        return min(score, 1.0)
    
    def _calculate_confidence_score(self, base_profile: Dict, patient_profile: PatientProfile, 
                                  audio_similarity: float) -> float:
        """Calculate overall confidence in the recommendation"""
        
        score = 0.0
        
        # Base profile completeness
        if base_profile:
            profile_completeness = len([k for k in ['therapeutic_applications', 'psychological_effects', 
                                                  'physiological_effects', 'target_conditions'] 
                                      if k in base_profile and base_profile[k]]) / 4
            score += profile_completeness * 0.3
        
        # Patient profile completeness
        personalization_score = self._calculate_personalization_score(patient_profile)
        score += personalization_score * 0.3
        
        # Audio similarity (if available)
        score += audio_similarity * 0.2
        
        # Condition matching
        condition_match = self._check_condition_match(base_profile, patient_profile)
        score += condition_match * 0.2
        
        return min(score, 1.0)
    
    def _check_condition_match(self, base_profile: Dict, patient_profile: PatientProfile) -> float:
        """Check how well the patient's condition matches the raga's target conditions - FIXED VERSION"""
        
        target_conditions = base_profile.get("target_conditions", [])
        patient_condition = patient_profile.mental_condition.lower()
        
        if not target_conditions:
            return 0.5  # Neutral if no target conditions specified
        
        # Check for direct matches
        for condition in target_conditions:
            if any(word in patient_condition for word in condition.lower().split()):
                return 1.0
        
        # Check for related conditions
        related_matches = 0
        for condition in target_conditions:
            condition_words = set(condition.lower().split())
            patient_words = set(patient_condition.split())
            if condition_words & patient_words:  # Intersection
                related_matches += 1
        
        if related_matches > 0:
            return min(related_matches / len(target_conditions), 1.0)
        
        return 0.3  # Low match if no clear relationship
    
# PART 7: HELPER METHODS AND STATISTICS

    def _generate_mock_audio_features(self) -> np.ndarray:
        """Generate mock audio features for demonstration"""
        # Simulate typical audio features (MFCC-like)
        return np.random.randn(50)  # 50-dimensional feature vector
    
    def _create_session_plan(self, recommendation: TherapyRecommendation) -> Dict[str, Any]:
        """Create a detailed therapy session plan"""
        
        return {
            "session_structure": {
                "preparation": "2-3 minutes of breathing exercises",
                "main_therapy": f"{recommendation.recommended_duration - 5} minutes of {recommendation.raga_name} music",
                "integration": "2-3 minutes of silent reflection"
            },
            "environment_setup": {
                "lighting": "dim, warm lighting" if "evening" in recommendation.best_time_of_day else "natural lighting",
                "seating": "comfortable chair or meditation cushion",
                "volume": "low to moderate (20-40% of maximum)",
                "distractions": "minimize all external noise and interruptions"
            },
            "monitoring_points": [
                "Patient's breathing pattern and depth",
                "Visible signs of relaxation or tension",
                "Emotional responses (tears, smiling, etc.)",
                "Any signs of distress or discomfort"
            ],
            "success_indicators": [
                "Slower, deeper breathing",
                "Relaxed facial expression",
                "Decreased muscle tension",
                "Positive verbal feedback"
            ]
        }
    
    def _generate_follow_up_notes(self, patient_profile: PatientProfile, 
                                 recommendation: TherapyRecommendation) -> Dict[str, Any]:
        """Generate follow-up notes and recommendations"""
        
        follow_up = {
            "immediate_post_session": [
                "Ask patient to rate their experience (1-10)",
                "Note any significant emotional responses",
                "Document physical changes observed",
                "Record patient's verbal feedback"
            ],
            "24_hour_follow_up": [
                "Check for any delayed emotional responses",
                "Assess sleep quality if applicable",
                "Note any changes in reported symptoms"
            ],
            "weekly_assessment": [
                "Evaluate overall progress toward therapy goals",
                "Adjust session duration if needed",
                "Consider alternative ragas if limited progress"
            ],
            "red_flags_to_monitor": [
                "Increased anxiety or distress during sessions",
                "No improvement after 4-6 sessions",
                "Patient resistance or strong negative reactions"
            ],
            "alternative_ragas": self._suggest_alternative_ragas(patient_profile),
            "complementary_therapies": [
                "Progressive muscle relaxation",
                "Breathing exercises",
                "Guided imagery",
                "Cognitive behavioral techniques"
            ]
        }
        
        return follow_up
    
    def _suggest_alternative_ragas(self, patient_profile: PatientProfile) -> List[str]:
        """Suggest alternative ragas based on patient profile"""
        
        condition = patient_profile.mental_condition.lower()
        
        if "anxiety" in condition:
            return ["Bhairav", "Yaman", "Kafi"]
        elif "depression" in condition:
            return ["Bilawal", "Yaman", "Bhairav"]
        elif "ptsd" in condition or "trauma" in condition:
            return ["Malkauns", "Todi", "Kafi"]
        elif "insomnia" in condition or "sleep" in condition:
            return ["Kafi", "Malkauns", "Yaman"]
        elif "adhd" in condition or "attention" in condition:
            return ["Bhairav", "Bilawal", "Yaman"]
        else:
            return ["Yaman", "Bhairav", "Kafi"]  # Safe defaults
    
    def _generate_therapy_description(self, base_profile: Dict, patient_profile: PatientProfile) -> str:
        """Generate therapy description for text embedding"""
        
        primary_emotion = base_profile.get("primary_emotion", "healing")
        applications = base_profile.get("therapeutic_applications", [])
        effects = base_profile.get("psychological_effects", [])
        
        description = f"Music therapy for {primary_emotion} and emotional healing. "
        
        if applications:
            description += f"Therapeutic applications include {', '.join(applications[:3])}. "
        
        if effects:
            description += f"Psychological effects include {', '.join(effects[:3])}. "
        
        description += f"Designed for {patient_profile.mental_condition} with {patient_profile.severity} severity level. "
        description += f"Suitable for {patient_profile.gender} patient aged {patient_profile.age}."
        
        return description
    
    def _generate_summary_statistics(self, therapy_mappings: List[Dict]) -> Dict[str, Any]:
        """Generate summary statistics from therapy mappings"""
        
        if not therapy_mappings:
            return {}
        
        # Extract data for analysis
        ragas = [mapping["raga_name"] for mapping in therapy_mappings]
        conditions = [mapping["patient_profile"]["mental_condition"] for mapping in therapy_mappings]
        severities = [mapping["patient_profile"]["severity"] for mapping in therapy_mappings]
        ages = [mapping["patient_profile"]["age"] for mapping in therapy_mappings]
        confidence_scores = [mapping["recommendation"]["confidence_score"] for mapping in therapy_mappings]
        durations = [mapping["recommendation"]["recommended_duration"] for mapping in therapy_mappings]
        
        # Calculate statistics
        summary = {
            "total_mappings": len(therapy_mappings),
            "unique_ragas": len(set(ragas)),
            "raga_distribution": {raga: ragas.count(raga) for raga in set(ragas)},
            "condition_distribution": {condition: conditions.count(condition) for condition in set(conditions)},
            "severity_distribution": {severity: severities.count(severity) for severity in set(severities)},
            "age_statistics": {
                "mean": np.mean(ages),
                "median": np.median(ages),
                "min": min(ages),
                "max": max(ages),
                "std": np.std(ages)
            },
            "confidence_statistics": {
                "mean": np.mean(confidence_scores),
                "median": np.median(confidence_scores),
                "min": min(confidence_scores),
                "max": max(confidence_scores),
                "std": np.std(confidence_scores)
            },
            "duration_statistics": {
                "mean": np.mean(durations),
                "median": np.median(durations),
                "min": min(durations),
                "max": max(durations),
                "std": np.std(durations)
            },
            "therapy_types": {},
            "most_recommended_raga": max(set(ragas), key=ragas.count),
            "most_common_condition": max(set(conditions), key=conditions.count),
            "average_confidence": np.mean(confidence_scores)
        }
        
        # Therapy types distribution
        therapy_types = [mapping["recommendation"]["therapy_type"] for mapping in therapy_mappings]
        summary["therapy_types"] = {therapy_type: therapy_types.count(therapy_type) 
                                  for therapy_type in set(therapy_types)}
        
        return summary
    
# PART 8: PDF AND REPORT GENERATION

    def _save_summary_report_pdf(self, results: Dict, summary_stats: Dict):
        """Save a PDF summary report using ReportLab"""
        
        if not REPORTLAB_AVAILABLE:
            # Fallback to text report
            self._save_summary_report_text(results, summary_stats)
            return
        
        report_file = os.path.join(self.mapping_folder, "therapy_mapping_report.pdf")
        
        try:
            # Create PDF document
            doc = SimpleDocTemplate(report_file, pagesize=A4)
            styles = getSampleStyleSheet()
            
            # Custom styles
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=16,
                spaceAfter=30,
                textColor=colors.darkblue,
                alignment=1  # Center alignment
            )
            
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontSize=12,
                spaceAfter=12,
                textColor=colors.darkgreen
            )
            
            # Content elements
            elements = []
            
            # Title
            elements.append(Paragraph("RAGA-THERAPY MAPPING SUMMARY REPORT", title_style))
            elements.append(Spacer(1, 12))
            
            # Generated timestamp
            elements.append(Paragraph(f"<b>Generated:</b> {results['timestamp']}", styles['Normal']))
            elements.append(Spacer(1, 20))
            
            # Overview section
            elements.append(Paragraph("OVERVIEW", heading_style))
            overview_data = [
                ["Metric", "Value"],
                ["Total therapy mappings created", f"{summary_stats.get('total_mappings', 0)}"],
                ["Unique ragas analyzed", f"{summary_stats.get('unique_ragas', 0)}"],
                ["Average confidence score", f"{summary_stats.get('average_confidence', 0):.3f}"],
                ["Most recommended raga", f"{summary_stats.get('most_recommended_raga', 'N/A')}"],
                ["Most common condition", f"{summary_stats.get('most_common_condition', 'N/A')}"]
            ]
            
            overview_table = Table(overview_data, colWidths=[3*inch, 2*inch])
            overview_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(overview_table)
            elements.append(Spacer(1, 20))
            
            # Raga Distribution
            elements.append(Paragraph("RAGA DISTRIBUTION", heading_style))
            raga_dist = summary_stats.get('raga_distribution', {})
            raga_data = [["Raga", "Patient Count", "Percentage"]]
            for raga, count in sorted(raga_dist.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / summary_stats.get('total_mappings', 1)) * 100
                raga_data.append([raga, str(count), f"{percentage:.1f}%"])
            
            raga_table = Table(raga_data, colWidths=[2*inch, 1.5*inch, 1.5*inch])
            raga_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(raga_table)
            elements.append(Spacer(1, 20))
            
            # Mental Condition Distribution
            elements.append(Paragraph("MENTAL CONDITION DISTRIBUTION", heading_style))
            condition_dist = summary_stats.get('condition_distribution', {})
            condition_data = [["Mental Condition", "Patient Count", "Percentage"]]
            for condition, count in sorted(condition_dist.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / summary_stats.get('total_mappings', 1)) * 100
                condition_data.append([condition, str(count), f"{percentage:.1f}%"])
            
            condition_table = Table(condition_data, colWidths=[2*inch, 1.5*inch, 1.5*inch])
            condition_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(condition_table)
            elements.append(Spacer(1, 20))
            
            # System Information
            elements.append(Paragraph("SYSTEM INFORMATION", heading_style))
            wav2clip_info = results.get('wav2clip_embeddings', {})
            raga_info = results.get('raga_detection_info', {})
            
            system_data = [
                ["Component", "Details"],
                ["Wav2CLIP Model", f"{wav2clip_info.get('model_used', 'N/A')}"],
                ["Embedding Dimension", f"{wav2clip_info.get('embedding_dimension', 'N/A')}"],
                ["Total Embeddings", f"{wav2clip_info.get('total_embeddings_created', 0)}"],
                ["Raga Detection Model", f"Available: {raga_info.get('model_available', False)}"],
                ["Predictions Processed", f"{raga_info.get('predictions_count', 0)}"]
            ]
            
            system_table = Table(system_data, colWidths=[2*inch, 3*inch])
            system_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            
            elements.append(system_table)
            
            # Build PDF
            doc.build(elements)
            print(f" PDF report saved: {report_file}")
            
        except Exception as e:
            logger.error(f"Failed to create PDF report: {e}")
            print(f" PDF generation failed: {e}")
            self._save_summary_report_text(results, summary_stats)
    
    def _save_summary_report_text(self, results: Dict, summary_stats: Dict):
        """Save a text summary report as fallback"""
        
        report_file = os.path.join(self.mapping_folder, "therapy_mapping_report.txt")
        
        with open(report_file, 'w') as f:
            f.write("RAGA-THERAPY MAPPING SUMMARY REPORT\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Generated: {results['timestamp']}\n\n")
            
            # Overview
            f.write("OVERVIEW:\n")
            f.write("-" * 20 + "\n")
            f.write(f"Total therapy mappings created: {summary_stats.get('total_mappings', 0)}\n")
            f.write(f"Unique ragas analyzed: {summary_stats.get('unique_ragas', 0)}\n")
            f.write(f"Average confidence score: {summary_stats.get('average_confidence', 0):.3f}\n")
            f.write(f"Most recommended raga: {summary_stats.get('most_recommended_raga', 'N/A')}\n")
            f.write(f"Most common condition: {summary_stats.get('most_common_condition', 'N/A')}\n\n")
            
            # Raga Distribution
            f.write("RAGA DISTRIBUTION:\n")
            f.write("-" * 20 + "\n")
            raga_dist = summary_stats.get('raga_distribution', {})
            for raga, count in sorted(raga_dist.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / summary_stats.get('total_mappings', 1)) * 100
                f.write(f"{raga}: {count} patients ({percentage:.1f}%)\n")
            f.write("\n")
            
            # System Info
            f.write("SYSTEM INFORMATION:\n")
            f.write("-" * 20 + "\n")
            f.write(f"Wav2CLIP model: {results['wav2clip_embeddings']['model_used']}\n")
            f.write(f"Embedding dimension: {results['wav2clip_embeddings']['embedding_dimension']}\n")
            f.write(f"Raga detection model available: {results['raga_detection_info']['model_available']}\n")
            f.write(f"Predictions processed: {results['raga_detection_info']['predictions_count']}\n")
        
        print(f" Text report saved: {report_file}")
    
    def _save_detailed_therapy_mappings(self, therapy_mappings: List[Dict]):
        """Save detailed therapy mappings with enhanced format"""
        
        detailed_output_file = os.path.join(self.mapping_folder, "detailed_therapy_mappings.json")
        
        # Enhanced format for better readability
        enhanced_mappings = []
        
        for mapping in therapy_mappings:
            enhanced_mapping = {
                "patient_information": {
                    "patient_id": mapping["patient_id"],
                    "demographics": {
                        "age": mapping["patient_profile"]["age"],
                        "gender": mapping["patient_profile"]["gender"]
                    },
                    "clinical_profile": {
                        "mental_condition": mapping["patient_profile"]["mental_condition"],
                        "severity_level": mapping["patient_profile"]["severity"],
                        "current_improvement_score": mapping["patient_profile"]["improvement_score"],
                        "preferred_listening_time": mapping["patient_profile"]["listening_time"]
                    }
                },
                "raga_assignment": {
                    "assigned_raga": mapping["raga_name"],
                    "detection_confidence": mapping.get("detection_confidence", 0.0),
                    "assignment_rationale": f"Selected based on therapeutic properties for {mapping['patient_profile']['mental_condition']}"
                },
                "therapy_recommendation": {
                    "therapy_type": mapping["recommendation"]["therapy_type"],
                    "mood_enhancement_expected": mapping["recommendation"]["mood_enhancement"],
                    "stress_reduction_level": mapping["recommendation"]["stress_reduction_level"],
                    "session_details": {
                        "recommended_duration_minutes": mapping["recommendation"]["recommended_duration"],
                        "optimal_time_of_day": mapping["recommendation"]["best_time_of_day"],
                        "confidence_in_recommendation": mapping["recommendation"]["confidence_score"]
                    },
                    "therapeutic_benefits": mapping["recommendation"]["therapeutic_benefits"],
                    "safety_considerations": mapping["recommendation"]["contraindications"]
                },
                "session_planning": mapping.get("therapy_session_plan", {}),
                "follow_up_protocol": mapping.get("follow_up_notes", {}),
                "quality_metrics": {
                    "personalization_score": mapping["recommendation"]["personalization_score"],
                    "audio_text_similarity": mapping["recommendation"]["audio_similarity_score"],
                    "overall_confidence": mapping["recommendation"]["confidence_score"]
                },
                "metadata": {
                    "mapping_created": mapping["mapping_timestamp"],
                    "wav2clip_processed": mapping["recommendation"]["audio_similarity_score"] > 0,
                    "system_version": "1.0"
                }
            }
            
            enhanced_mappings.append(enhanced_mapping)
        
        # Save enhanced mappings
        with open(detailed_output_file, 'w') as f:
            json.dump(enhanced_mappings, f, indent=2, default=str)
        
        print(f" Enhanced detailed mappings saved: {detailed_output_file}")
        
        return enhanced_mappings
    
    def _save_therapy_templates(self, therapy_mappings: List[Dict]):
        """Save therapy session templates for practitioners"""
        
        templates_file = os.path.join(self.mapping_folder, "therapy_session_templates.json")
        
        # Group by raga to create templates
        raga_templates = {}
        
        for mapping in therapy_mappings:
            raga = mapping["raga_name"]
            if raga not in raga_templates:
                raga_templates[raga] = {
                    "raga_name": raga,
                    "therapy_profile": self.therapy_profiles.get(raga, {}),
                    "sample_sessions": [],
                    "practitioner_notes": {
                        "preparation": f"Ensure quiet environment for {raga} therapy session",
                        "during_session": "Monitor patient responses and adjust volume as needed",
                        "post_session": "Document patient feedback and any notable reactions"
                    }
                }
            
            # Add sample session
            if len(raga_templates[raga]["sample_sessions"]) < 3:  # Limit to 3 samples per raga
                session_template = {
                    "patient_type": f"{mapping['patient_profile']['mental_condition']} - {mapping['patient_profile']['severity']}",
                    "session_plan": mapping.get("therapy_session_plan", {}),
                    "expected_outcomes": mapping["recommendation"]["therapeutic_benefits"],
                    "duration": mapping["recommendation"]["recommended_duration"],
                    "contraindications": mapping["recommendation"]["contraindications"]
                }
                raga_templates[raga]["sample_sessions"].append(session_template)
        
        # Save templates
        with open(templates_file, 'w') as f:
            json.dump(raga_templates, f, indent=2, default=str)
        
        print(f" Therapy templates saved: {templates_file}")

# PART 9: MAIN PROCESSING FUNCTION

    def process_therapy_mapping(self) -> Dict[str, Any]:
        """Main function to process therapy mapping - CORRECTED VERSION"""
        
        print(" STARTING RAGA-THERAPY MAPPING SYSTEM")
        print("=" * 60)
        
        # Step 1: Check if raga detection has been run
        print(" Step 1: Checking raga detection output...")
        
        if not self.check_raga_detection_output():
            print("  Raga detection output not found, creating sample data for demonstration...")
            # Create sample raga detection results for demonstration
            os.makedirs("results/json_values", exist_ok=True)
            
            # Create sample performance file
            sample_performance = {
                "accuracy": 0.85,
                "precision": 0.83,
                "recall": 0.87,
                "f1_score": 0.85,
                "model_type": "Enhanced CNN",
                "training_time": "45 minutes"
            }
            
            with open("results/json_values/enhanced_model_performance.json", 'w') as f:
                json.dump(sample_performance, f, indent=2)
            
            # Create sample prediction file
            sample_prediction = {
                "audio_file": "sample_audio.wav",
                "predicted_raga": "Yaman",
                "confidence": 0.85,
                "top_3_predictions": [
                    {"raga": "Yaman", "confidence": 0.85},
                    {"raga": "Kafi", "confidence": 0.12},
                    {"raga": "Bhairav", "confidence": 0.03}
                ],
                "timestamp": datetime.now().isoformat(),
                "processing_time": 2.34
            }
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            with open(f"results/json_values/enhanced_prediction_{timestamp}.json", 'w') as f:
                json.dump(sample_prediction, f, indent=2)
            
            print(" Sample raga detection data created!")
        else:
            print(" Raga detection output found!")
        
        # Step 2: Load raga detection results
        print("\n Step 2: Loading raga detection results...")
        raga_results = self.load_raga_detection_results()
        
        if not raga_results["model_performance"] and not raga_results["predictions"]:
            error_msg = "No valid raga detection results found."
            print(f" {error_msg}")
            return {
                "status": "error", 
                "message": error_msg,
                "timestamp": datetime.now().isoformat()
            }
        
        print(f" Loaded {len(raga_results['predictions'])} predictions")
        if raga_results["model_performance"]:
            accuracy = raga_results["model_performance"].get("accuracy", 0)
            print(f" Model accuracy: {accuracy:.3f}")
        
        # Step 3: Load therapy dataset - FIXED TO NEVER FAIL
        print("\n Step 3: Loading therapy dataset...")
        
        # This will never be empty now due to our fixes
        print(f" Loaded therapy dataset: {self.therapy_dataset.shape}")
        print(f" Available features: {list(self.therapy_dataset.columns)}")
        
        # Step 4: Create therapy mappings
        print("\n Step 4: Creating therapy mappings...")
        
        therapy_mappings = []
        
        # Get the latest prediction for reference
        latest_prediction = None
        if raga_results["predictions"]:
            latest_prediction = raga_results["predictions"][-1]
            predicted_raga = latest_prediction.get('predicted_raga', 'Unknown')
            confidence = latest_prediction.get('confidence', 0)
            print(f" Latest prediction: {predicted_raga} (confidence: {confidence:.3f})")
        
        # Process each patient in the therapy dataset
        for idx, row in self.therapy_dataset.iterrows():
            try:
                # Create patient profile with proper error handling
                patient_profile = PatientProfile(
                    age=int(row.get('Age', 30)),
                    gender=str(row.get('Gender', 'Unknown')),
                    mental_condition=str(row.get('Mental_Condition', 'General')),
                    severity=str(row.get('Severity', 'Moderate')),
                    improvement_score=float(row.get('Improvement_Score', 0.5)),
                    listening_time=float(row.get('Listening_Time', 30))
                )
                
                # Get raga (from dataset or use detected raga if available)
                raga_name = str(row.get('Raga', 'Unknown'))
                
                # If we have a recent prediction and it's reliable, use it for first few patients
                if (latest_prediction and 
                    isinstance(latest_prediction, dict) and 
                    'predicted_raga' in latest_prediction and
                    latest_prediction.get('confidence', 0) > 0.5 and
                    idx < 3):  # Use detected raga for first 3 patients as example
                    raga_name = latest_prediction['predicted_raga']
                    print(f" Using detected raga '{raga_name}' for patient {idx}")
                
                # Create recommendation with audio features for first patient
                audio_features = self._generate_mock_audio_features() if idx == 0 else None
                
                recommendation = self.create_personalized_recommendation(
                    raga_name=raga_name,
                    patient_profile=patient_profile,
                    audio_features=audio_features
                )
                
                # Create comprehensive mapping entry
                mapping_entry = {
                    "patient_id": f"P{idx:03d}",
                    "raga_name": raga_name,
                    "patient_profile": patient_profile.__dict__,
                    "recommendation": recommendation.__dict__,
                    "mapping_timestamp": datetime.now().isoformat(),
                    "detection_confidence": latest_prediction.get('confidence', 0.0) if (latest_prediction and idx < 3) else 0.0,
                    "therapy_session_plan": self._create_session_plan(recommendation),
                    "follow_up_notes": self._generate_follow_up_notes(patient_profile, recommendation)
                }
                
                therapy_mappings.append(mapping_entry)
                
                # Print progress for first few and every 5th
                if idx < 5 or idx % 5 == 0:
                    print(f"    Created mapping for Patient {idx}: {patient_profile.mental_condition} -> {raga_name}")
                
            except Exception as e:
                logger.warning(f"Failed to process patient {idx}: {e}")
                continue
        
        print(f" Created {len(therapy_mappings)} therapy mappings")
        
        # Print sample mappings for verification
        if therapy_mappings:
            print(f"\n SAMPLE THERAPY MAPPINGS:")
            for i, mapping in enumerate(therapy_mappings[:3]):
                patient = mapping["patient_profile"]
                rec = mapping["recommendation"]
                print(f"   {i+1}. Patient {mapping['patient_id']}:")
                print(f"       Condition: {patient['mental_condition']} ({patient['severity']})")
                print(f"       Raga: {mapping['raga_name']}")
                print(f"       Therapy: {rec['therapy_type']}")
                print(f"       Duration: {rec['recommended_duration']} minutes")
                print(f"       Confidence: {rec['confidence_score']:.3f}")
                print()
        
        # Step 5: Generate summary statistics
        print("\n Step 5: Generating summary statistics...")
        
        summary_stats = self._generate_summary_statistics(therapy_mappings)
        
        # Step 6: Save results
        print("\n Step 6: Saving mapping results...")
        
        results = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "raga_detection_info": {
                "model_available": raga_results["classifier_available"],
                "predictions_count": len(raga_results["predictions"]),
                "model_performance": raga_results["model_performance"]
            },
            "therapy_dataset_info": {
                "total_patients": len(self.therapy_dataset),
                "features": list(self.therapy_dataset.columns),
                "unique_ragas": self.therapy_dataset['Raga'].nunique() if 'Raga' in self.therapy_dataset.columns else 0
            },
            "therapy_mappings": therapy_mappings,
            "summary_statistics": summary_stats,
            "wav2clip_embeddings": {
                "model_used": self.embedder.model_name,
                "embedding_dimension": 256,
                "total_embeddings_created": len(therapy_mappings)
            }
        }
        
        # Save main results
        main_output_file = os.path.join(self.mapping_folder, "therapy_mapping_results.json")
        with open(main_output_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # Save detailed mappings with enhanced format
        enhanced_mappings = self._save_detailed_therapy_mappings(therapy_mappings)
        
        # Save therapy session templates
        self._save_therapy_templates(therapy_mappings)
        
        # Save summary report (PDF if available, otherwise text)
        if REPORTLAB_AVAILABLE:
            self._save_summary_report_pdf(results, summary_stats)
        else:
            self._save_summary_report_text(results, summary_stats)
            print(" Install reportlab for PDF reports: pip install reportlab")
        
        print(f" Results saved to {self.mapping_folder}/")
        print(f" Main results: {main_output_file}")
        print(f" Enhanced mappings: {self.mapping_folder}/detailed_therapy_mappings.json")
        print(f" Session templates: {self.mapping_folder}/therapy_session_templates.json")
        
        # Step 7: Display results
        self._display_results_summary(results, summary_stats)
        
        return results
    
    def _display_results_summary(self, results: Dict, summary_stats: Dict):
        """Display results summary to console"""
        
        print("\n THERAPY MAPPING COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        
        print(f" SUMMARY STATISTICS:")
        print(f"   Total mappings created: {summary_stats.get('total_mappings', 0)}")
        print(f"   Unique ragas analyzed: {summary_stats.get('unique_ragas', 0)}")
        print(f"   Average confidence: {summary_stats.get('average_confidence', 0):.3f}")
        print(f"   Most recommended raga: {summary_stats.get('most_recommended_raga', 'N/A')}")
        
        print(f"\n TOP RAGAS:")
        raga_dist = summary_stats.get('raga_distribution', {})
        top_ragas = sorted(raga_dist.items(), key=lambda x: x[1], reverse=True)[:3]
        for i, (raga, count) in enumerate(top_ragas, 1):
            print(f"   {i}. {raga}: {count} patients")
        
        print(f"\n TOP CONDITIONS:")
        condition_dist = summary_stats.get('condition_distribution', {})
        top_conditions = sorted(condition_dist.items(), key=lambda x: x[1], reverse=True)[:3]
        for i, (condition, count) in enumerate(top_conditions, 1):
            print(f"   {i}. {condition}: {count} patients")
        
        print(f"\n THERAPY TYPES:")
        therapy_types = summary_stats.get('therapy_types', {})
        for therapy_type, count in list(therapy_types.items())[:3]:
            print(f"    {therapy_type}: {count} patients")
        
        duration_stats = summary_stats.get('duration_statistics', {})
        print(f"\n SESSION DURATIONS:")
        print(f"   Average: {duration_stats.get('mean', 0):.1f} minutes")
        print(f"   Range: {duration_stats.get('min', 0)}-{duration_stats.get('max', 0)} minutes")
        
        print(f"\n OUTPUT FILES:")
        report_type = "PDF" if REPORTLAB_AVAILABLE else "TXT"
        print(f"    Main results: {self.mapping_folder}/therapy_mapping_results.json")
        print(f"    Enhanced mappings: {self.mapping_folder}/detailed_therapy_mappings.json")
        print(f"    Summary report: {self.mapping_folder}/therapy_mapping_report.{report_type.lower()}")
        
        print(f"\n WAV2CLIP EMBEDDING INFO:")
        wav2clip_info = results.get('wav2clip_embeddings', {})
        print(f"   Model: {wav2clip_info.get('model_used', 'N/A')}")
        print(f"   Embedding dimension: {wav2clip_info.get('embedding_dimension', 'N/A')}")
        print(f"   Total embeddings: {wav2clip_info.get('total_embeddings_created', 0)}")

# PART 10: MAIN EXECUTION AND ENTRY POINT

def main():
    """Main function to run therapy mapping - CORRECTED VERSION"""
    
    print(" WAV2CLIP RAGA-THERAPY MAPPING SYSTEM")
    print("Using audio-text embeddings for personalized music therapy")
    print("=" * 70)
    
    try:
        # Initialize therapy mapper
        print(" Initializing therapy mapping system...")
        mapper = RagaTherapyMapper()
        
        # Process therapy mapping
        results = mapper.process_therapy_mapping()
        
        if results["status"] == "success":
            print("\n THERAPY MAPPING COMPLETED SUCCESSFULLY!")
            print("\n Next steps:")
            print("   1. Review the generated therapy recommendations")
            print("   2. Validate mappings with healthcare professionals")
            print("   3. Use recommendations for personalized music therapy sessions")
            print("   4. Collect feedback for system improvement")
            
            # Additional information about files created
            print(f"\n Output Directory: mapping_output/")
            print(f"    therapy_mapping_results.json - Main results")
            print(f"    detailed_therapy_mappings.json - Detailed patient mappings")
            print(f"    therapy_session_templates.json - Session templates for practitioners")
            report_ext = "pdf" if REPORTLAB_AVAILABLE else "txt"
            print(f"    therapy_mapping_report.{report_ext} - Summary report")
            
        else:
            print(f"\n THERAPY MAPPING FAILED: {results['message']}")
            print(" Please check the requirements and try again.")
        
        return results
        
    except Exception as e:
        logger.error(f"Therapy mapping failed: {e}")
        print(f"\n UNEXPECTED ERROR: {e}")
        print(" Please check your setup and try again.")
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    print(" Wav2CLIP Raga-Therapy Mapping System")
    print("=" * 50)
    print("\n Requirements:")
    print("1. Run raga_detection.py first (or system will create sample data)")
    print("2. Ensure data/Final_dataset_s.csv exists (or system will create sample data)")
    print("3. Install required packages:")
    print("   pip install torch transformers librosa scikit-learn pandas")
    print("   pip install reportlab  # Optional, for PDF reports")
    print("\n Starting therapy mapping...")
    
    # Check if the specific files exist
    performance_file = "results/json_values/enhanced_model_performance.json"
    prediction_pattern = "results/json_values/enhanced_prediction_*.json"
    dataset_file = "data/Final_dataset_s.csv"
    
    print(f"\n Checking files:")
    if os.path.exists(performance_file):
        print(f" Found performance file: {performance_file}")
    else:
        print(f"  Performance file not found: {performance_file}")
    
    # Check for prediction files
    prediction_files = glob.glob(prediction_pattern)
    if prediction_files:
        print(f" Found {len(prediction_files)} prediction files")
        for pf in prediction_files[:3]:  # Show first 3
            print(f"    {pf}")
    else:
        print(f"  No prediction files found matching: {prediction_pattern}")
    
    # Check for dataset file
    if os.path.exists(dataset_file):
        print(f" Found dataset file: {dataset_file}")
    else:
        print(f"  Dataset file not found: {dataset_file}")
        print("    System will create comprehensive sample data automatically")
    
    print("\n" + "="*50)
    
    # Run main function
    results = main()
    
    if results["status"] == "success":
        print("\n Therapy mapping completed successfully!")
        print(f" Check the 'mapping_output' folder for results")
        
        # Print quick stats
        stats = results.get("summary_statistics", {})
        if stats:
            print(f"\n Quick Stats:")
            print(f"    {stats.get('total_mappings', 0)} therapy mappings created")
            print(f"    {stats.get('unique_ragas', 0)} unique ragas analyzed")
            print(f"    {stats.get('average_confidence', 0):.1%} average confidence")
    else:
        print(f"\n Failed: {results.get('message', 'Unknown error')}")
        print(" Check the error messages above for troubleshooting")
    
    print("\n Thank you for using the Raga-Therapy Mapping System!")
    
    # Keep window open on Windows
    if os.name == 'nt':  # Windows
        input("\nPress Enter to exit...")
        
