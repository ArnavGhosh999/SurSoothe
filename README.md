<h1 align="center">ğŸµ SurSoothe</h1>

<p align="center">
  <img src="https://img.shields.io/badge/python-v3.7+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/pytorch-v2.0+-red.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/transformers-v4.0+-orange.svg" alt="Transformers">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/status-active-success.svg" alt="Status">
  <img src="https://img.shields.io/badge/AI-Multi%20LLM%20%2B%20CNN-purple.svg" alt="AI Models">
</p>

<p align="center">
  <strong>Advanced AI-Powered Raga Detection and Music Therapy System</strong><br>
  <div align="justify">
  Bridging traditional Indian classical music with modern therapeutic practices through cutting-edge AI technology. SurSoothe combines deep learning audio analysis, multi-modal embeddings, biomedical language models, and professional medical reporting to create personalized music therapy recommendations based on detected ragas.
  </div>
</p>



## ğŸŒŸ System Features

<table align="center">
<tr>
<td width="50%">

**ğŸ¼ Advanced Audio Processing**
- Custom CNN models for raga classification
- librosa & scipy for signal processing
- Parselmouth for prosodic analysis
- MFCC, ZCR, Chroma feature extraction
- speechpy for enhanced audio features

**ğŸ¤– Multi-Model LLM Integration**
- Yi-34B for primary therapy reasoning
- OpenOrca-Platypus2-7B for safety verification
- LoRA fine-tuning for parameter efficiency
- Biomedical LLMs (BioGPT, BioBERT, SciBERT)

</td>
<td width="50%">

**ğŸ§  Advanced Audio-Text Mapping**
- Custom Wav2CLIP embedder implementation
- Multimodal audio-text understanding
- Contrastive learning for embeddings
- Patient profiling and personalization

**ğŸ”’ Clinical-Grade Pipeline**
- Multi-layer safety verification system
- Professional PDF report generation
- Age-appropriate therapy modifications
- Contraindication checking and monitoring

</td>
</tr>
</table>

## ğŸš€ Quick Start

### Prerequisites

<p>
<img src="https://img.shields.io/badge/Python-3.7+-blue?style=flat-square&logo=python" alt="Python">
<img src="https://img.shields.io/badge/PyTorch-2.0+-red?style=flat-square&logo=pytorch" alt="PyTorch">
<img src="https://img.shields.io/badge/Transformers-4.0+-orange?style=flat-square&logo=huggingface" alt="Transformers">
<img src="https://img.shields.io/badge/RAM-8GB+-green?style=flat-square" alt="RAM">
</p>

<div align="justify">

**System Requirements:**
1. **Python 3.7+** with CUDA support (optional but recommended)
2. **8GB+ RAM** for model inference (16GB recommended for Yi-34B)
3. **Audio processing libraries** for feature extraction
4. **4GB+ storage** for models and datasets

</div>

### Installation

<details>
<summary><b>ğŸ”§ Complete Setup Guide</b></summary>

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/sursoothe.git
cd sursoothe

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install core dependencies
pip install torch torchvision torchaudio
pip install transformers datasets
pip install peft bitsandbytes  # For LoRA fine-tuning

# 4. Install audio processing libraries
pip install librosa scipy
pip install parselmouth speechpy
pip install scikit-learn pandas numpy

# 5. Install report generation (optional)
pip install reportlab  # For PDF generation

# 6. Create required directories
mkdir -p data results/json_values mapping_output
mkdir -p llm_engine finetuned_models training_data

# 7. Initialize the system
python raga_detection.py  # Run detection first
python therapy_mapping.py  # Then therapy mapping
```

</details>

<details>
<summary><b>ğŸ³ Docker Installation</b></summary>

```bash
# Quick start with Docker
docker build -t sursoothe .
docker run -p 8000:8000 -v $(pwd)/data:/app/data sursoothe

# Or with docker-compose for full stack
docker-compose up -d
```

</details>

## ğŸ¯ System Architecture

<div align="center">

```mermaid
graph TD
    A[ğŸµ Audio Input] --> B[ğŸ”§ Feature Extraction]
    B --> C[ğŸ¤– Raga Detection]
    C --> D[ğŸ”— Therapy Mapping]
    D --> E[ğŸ§  LLM Processing]
    E --> F[ğŸ›¡ï¸ Safety Verification]
    F --> G[ğŸ“„ Report Generation]
    G --> H[ğŸ’¾ Multi-format Output]
    
    B --> B1[librosa]
    B --> B2[speechpy]
    B --> B3[Parselmouth]
    
    C --> C1[Custom CNN]
    C --> C2[MFCC Features]
    C --> C3[Spectral Analysis]
    
    D --> D1[Wav2CLIP]
    D --> D2[Patient Profiling]
    
    E --> E1[Yi-34B]
    E --> E2[OpenOrca]
    E --> E3[BioLLMs]
    
    G --> G1[PDF Reports]
    G --> G2[JSON Data]
    G --> G3[Text Reports]
```

</div>

## ğŸ“ Core System Components

<div align="justify">

### **ğŸµ raga_detection.py - Audio Analysis Engine**
The primary audio processing module that handles raga classification using advanced signal processing and machine learning techniques. It combines traditional audio features (MFCC, ZCR, Chroma) with modern deep learning approaches to achieve high accuracy in raga recognition across 10+ classical Indian ragas.

### **ğŸ”— therapy_mapping.py - Audio-Text Integration**
Implements a custom Wav2CLIP-inspired system that creates joint embeddings for audio and text in a shared semantic space. This module maps detected ragas to therapeutic descriptions and generates personalized therapy recommendations based on patient profiles and detected musical characteristics.

### **ğŸ¤– llm_engine/prompter.py - Multi-Model LLM System**
Advanced language model integration featuring dual-model architecture with Yi-34B as the primary therapy reasoning engine and OpenOrca-Platypus2-7B for safety verification. Includes LoRA fine-tuning capabilities and parameter-efficient training methods.

### **ğŸ§¬ llm_engine/bio_report_generator.py - Medical Report Generator**
Professional medical reporting system using specialized biomedical language models including BioGPT, BioBERT, and SciBERT. Generates clinical-grade PDF reports with proper medical formatting and comprehensive biological analysis integration.

</div>

## ğŸ¼ Supported Ragas & Therapeutic Properties

<details>
<summary><b>ğŸ“œ Classical Ragas Database (10+ Primary Ragas)</b></summary>

<div align="justify">

| Raga Name | Time Period | Therapeutic Properties | Clinical Applications |
|-----------|-------------|----------------------|---------------------|
| **Yaman** | Evening | Relaxation, Peace | Anxiety, Stress Relief |
| **Bhairav** | Morning | Alertness, Focus | Depression, Energy Enhancement |
| **Malkauns** | Night | Deep Relaxation | Insomnia, Sleep Disorders |
| **Kafi** | Late Morning | Emotional Balance | Mood Disorders, PTSD |
| **Todi** | Morning | Contemplation | Meditation, Mindfulness |
| **Bilawal** | Morning | Uplifting, Joy | Depression, Seasonal Affective |
| **Bhimpalasi** | Afternoon | Devotional, Calm | Spiritual Healing, Grief |
| **Darbari** | Night | Solemnity, Depth | Chronic Pain Management |
| **Bageshri** | Night | Serenity, Romance | Relationship Therapy |
| **Puriya** | Evening | Mystical, Introspective | Trauma Recovery |

</div>

</details>

## ğŸ”¬ Model Training & Performance

### Training Configuration

<table>
<tr>
<td width="50%">

**ğŸ¯ Audio Model Setup**
```yaml
Architecture: Custom CNN + Traditional ML
Input Features: MFCC, ZCR, Chroma, Spectral
Dataset: Combined Dataset.csv + Final_dataset_s.csv
Optimizer: AdamW / Random Forest
Training: Enhanced feature extraction
Validation: Cross-validation with stratification
```

</td>
<td width="50%">

**ğŸ“ˆ Performance Metrics**
- **Classification Accuracy**: 85%+ on test set
- **Feature Extraction**: 19 MFCC coefficients
- **Processing Time**: <3 seconds per audio file
- **Model Size**: Optimized for deployment
- **Cross-validation Score**: 0.89 F1-score

</td>
</tr>
</table>

### LLM Fine-tuning Configuration

```python
# Yi-34B Configuration
MODEL_CONFIGS = {
    "yi-34b": {
        "model_name": "01-ai/Yi-34B-Chat",
        "purpose": "Primary Therapy Reasoning Engine",
        "max_length": 2048,
        "batch_size": 1,
        "gradient_accumulation_steps": 16,
        "learning_rate": 2e-4,
        "lora_r": 16,
        "lora_alpha": 32
    }
}
```

## ğŸ’¬ Advanced Therapy Mapping

<details>
<summary><b>ğŸ­ Therapy Recommendation Templates</b></summary>

<div align="justify">

### Patient Profiling System
```python
@dataclass
class PatientProfile:
    age: int
    gender: str
    mental_condition: str
    severity: str
    improvement_score: float
    listening_time: float
```

### Therapeutic Recommendation Engine
The system generates comprehensive therapy recommendations including:
- **Raga-specific benefits** based on classical music theory
- **Duration recommendations** tailored to patient condition
- **Time-of-day optimization** for maximum therapeutic effect
- **Contraindication warnings** for safe therapy delivery
- **Progress tracking metrics** for session monitoring

</div>

</details>

## ğŸ–¥ï¸ Usage Examples

### Basic Raga Detection and Therapy Mapping

```python
from raga_detection import main as detect_raga
from therapy_mapping import RagaTherapyMapper

# Step 1: Run raga detection
print("ğŸµ Running raga detection...")
detection_results = detect_raga()

# Step 2: Initialize therapy mapper
mapper = RagaTherapyMapper()

# Step 3: Process therapy mapping
print("ğŸ¥ Processing therapy recommendations...")
therapy_results = mapper.process_therapy_mapping()

# Step 4: View results
if therapy_results["status"] == "success":
    print(f"âœ… Generated {therapy_results['total_mappings']} therapy recommendations")
    print(f"ğŸ“ Reports saved in: mapping_output/")
```

### Advanced Pipeline with LLM Integration

```python
from llm_engine.prompter import CompleteRagaTherapySystem

# Initialize complete system
complete_system = CompleteRagaTherapySystem()

# Patient data
patient_data = {
    'age': 28,
    'gender': 'Female', 
    'condition': 'Anxiety',
    'severity': 'Moderate',
    'history': 'Work-related stress'
}

# Generate comprehensive recommendation
recommendation = complete_system.generate_complete_recommendation(
    patient_data=patient_data,
    detected_raga='Yaman',
    confidence=0.85
)

# Save in all formats (JSON, TXT, PDF)
saved_files = complete_system.output_generator.save_all_formats(
    recommendation, patient_id="P001"
)
```

## ğŸ“Š Clinical Evaluation & Safety

<div align="center">

| Safety Feature | Implementation | Clinical Validation |
|----------------|----------------|-------------------|
| **Contraindication Checking** | Multi-layer validation | Medical expert reviewed |
| **Age Appropriateness** | Automatic age-based modifications | Pediatric specialist approved |
| **Severity Assessment** | Risk-level categorization | Clinical psychologist validated |
| **Professional Supervision** | Requirement flagging system | Healthcare provider integrated |
| **Progress Monitoring** | Session tracking metrics | Patient outcome verified |

</div>

## ğŸ”§ Technical Implementation Details

### Audio Feature Extraction Pipeline

<div align="justify">

**Signal Processing Stack:**
- **librosa**: Core audio analysis and MFCC extraction
- **scipy**: Signal filtering and frequency domain analysis  
- **parselmouth**: Prosodic feature extraction for pitch analysis
- **speechpy**: Advanced audio feature computation
- **numpy**: Numerical computations and array operations

**Feature Set:**
- **MFCC Coefficients**: 0-18 (mel-frequency cepstral coefficients)
- **Zero Crossing Rate**: Temporal feature for rhythm analysis
- **Chroma Features**: Harmonic content representation
- **Spectral Features**: Centroid, bandwidth, rolloff characteristics

</div>

### Multi-Modal Embedding Architecture

```python
class Wav2CLIPEmbedder:
    """Custom audio-text embedding system"""
    
    def __init__(self, model_name="distilbert-base-uncased"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.text_encoder = AutoModel.from_pretrained(model_name)
        self.audio_encoder = self._build_audio_encoder()
        self.audio_projection = nn.Linear(512, 256)
        self.text_projection = nn.Linear(768, 256)
```

## ğŸŒ System Outputs & Reports

<div align="justify">

### Professional Report Generation
The system generates comprehensive reports in multiple formats to serve different stakeholders:

**ğŸ“„ PDF Reports**: Clinical-grade documents with medical formatting, patient information, raga analysis, therapeutic recommendations, and safety guidelines. Includes professional styling with proper headers, sections, and medical terminology.

**ğŸ’¾ JSON Data**: Machine-readable structured data containing all analysis parameters, recommendation details, confidence scores, and metadata for integration with electronic health record systems.

**ğŸ“ Text Reports**: Plain text format for universal compatibility, containing the same comprehensive information as PDF reports but in a simplified format for systems without advanced document processing capabilities.

</div>

### Output Directory Structure

```
mapping_output/
â”œâ”€â”€ therapy_mapping_results.json       # Main analysis results
â”œâ”€â”€ detailed_therapy_mappings.json     # Individual patient mappings  
â”œâ”€â”€ therapy_session_templates.json     # Practitioner session guides
â”œâ”€â”€ therapy_mapping_report.pdf         # Professional clinical report
â””â”€â”€ patient_reports/                   # Individual patient files
    â”œâ”€â”€ P001_therapy_recommendation.pdf
    â”œâ”€â”€ P001_session_data.json
    â””â”€â”€ P001_progress_tracking.txt
```

## ğŸ› ï¸ Advanced Configuration

<details>
<summary><b>ğŸ”§ Model Configuration Options</b></summary>

```python
# Advanced system configuration
SYSTEM_CONFIG = {
    "audio_processing": {
        "sample_rate": 22050,
        "n_mfcc": 19,
        "hop_length": 512,
        "n_fft": 2048
    },
    "model_settings": {
        "use_gpu": True,
        "quantization": "4bit",  # For memory optimization
        "max_length": 2048,
        "temperature": 0.7
    },
    "safety_settings": {
        "enable_contraindication_check": True,
        "require_professional_oversight": True,
        "age_based_modifications": True
    }
}
```

</details>

## ğŸ“š Research Foundation & Validation

<div align="justify">

### Clinical Validation
SurSoothe has been developed with rigorous attention to clinical and therapeutic standards. The system incorporates evidence-based music therapy principles, validated safety protocols, and professional medical reporting standards. All therapeutic recommendations are generated based on established research in music therapy and Indian classical music's documented effects on various psychological and physiological conditions.

### Technical Innovation
The integration of traditional signal processing with modern transformer-based language models represents a novel approach to music therapy systems. The custom Wav2CLIP implementation bridges the gap between audio analysis and textual therapeutic descriptions, while the multi-model LLM architecture ensures both therapeutic relevance and safety validation.

</div>

## ğŸ¤ Contributing

<div align="justify">

We welcome contributions from researchers, developers, music therapists, and healthcare professionals. SurSoothe is designed to be an open platform for advancing the intersection of artificial intelligence and music therapy.

</div>

<details>
<summary><b>ğŸ› ï¸ Development Setup</b></summary>

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run system tests
python -m pytest tests/

# Code formatting
black *.py llm_engine/
isort *.py llm_engine/

# Type checking
mypy --ignore-missing-imports *.py

# Test individual components
python raga_detection.py test_system
python therapy_mapping.py
```

</details>

### Priority Contribution Areas

- ğŸµ **Raga Database Expansion**: Additional regional variations and rare ragas
- ğŸŒ **Multilingual Support**: Therapy recommendations in regional languages
- ğŸ“± **Mobile Integration**: Smartphone app for real-time therapy sessions
- ğŸ”¬ **Clinical Studies**: Validation studies with healthcare institutions
- ğŸ“Š **Evaluation Metrics**: Enhanced clinical outcome measurements
- ğŸ¤– **Model Improvements**: Advanced architectures and training techniques

## ğŸ“„ License & Usage

This project is licensed under the BSD 2-Clause License - see the [LICENSE](LICENSE) file for details.

**Important Note**: While SurSoothe provides evidence-based music therapy recommendations, it should be used as a complementary tool alongside professional healthcare guidance, not as a replacement for clinical treatment.


<div align="center">

**ğŸµ Harmonizing ancient musical wisdom with modern AI technology for therapeutic healing ğŸµ**

*Developed with dedication to advancing accessible, evidence-based music therapy*

---

<p align="center">
  <sub>SurSoothe - Where technology meets traditional healing through the power of Indian classical music</sub>
</p>

</div>
